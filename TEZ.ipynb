{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TEZ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18DHcaHq9Y3ooidf5ZjO5ANgIVAaUnxHP",
      "authorship_tag": "ABX9TyPRfdmewaIyR/H+JkcYDB9F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SelinZ/Biosignal-Emotions-BHS-2020/blob/master/TEZ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JNZ9H_TnsTa",
        "outputId": "110924b5-5a82-453f-e46b-e132fa6919a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymatreader\n",
            "  Downloading pymatreader-0.0.30-py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pymatreader) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pymatreader) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from pymatreader) (3.1.0)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: scipy!=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pymatreader) (1.4.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->pymatreader) (1.5.2)\n",
            "Installing collected packages: xmltodict, pymatreader\n",
            "Successfully installed pymatreader-0.0.30 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "! pip install pymatreader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIlHIfkeynPp",
        "outputId": "e8f75417-54c4-4cc8-eeca-e5ada482c5d6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0+zzzcolab20220506162203)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!  pip install mne"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7bcHNnenwOx",
        "outputId": "5349347a-bac4-491c-8d99-c884dd9c223e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mne\n",
            "  Downloading mne-1.0.3-py3-none-any.whl (7.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5 MB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mne) (4.64.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mne) (21.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mne) (3.2.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.7/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mne) (2.11.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mne) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mne) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mne) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mne) (1.15.0)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import mne\n",
        "import pymatreader\n",
        "%matplotlib inline\n",
        "from scipy.io import loadmat \n",
        "import mne, glob \n",
        "from numpy import loadtxt\n",
        "from pymatreader import read_mat\n",
        "from pylab import rcParams"
      ],
      "metadata": {
        "id": "QM2gaVfrnwRS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')"
      ],
      "metadata": {
        "id": "ojIpTUR5pEKd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/tmp/to_upload.txt', 'w') as f:\n",
        "  f.write('my sample file')\n",
        "\n",
        "print('/tmp/to_upload.txt contains:')\n",
        "!cat /tmp/to_upload.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqI6TPUTp6wq",
        "outputId": "dded8bef-51f2-4352-909b-bdf3739e4cae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/to_upload.txt contains:\n",
            "my sample file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = open('/Features14.csv')\n",
        "\n",
        "# let's print what it looks like...\n",
        "print(type(features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU3TEi-ynwTq",
        "outputId": "361fdef3-2a28-4098-8639-6c534279669b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '_io.TextIOWrapper'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        " \n",
        "df = pd.read_csv('/Features14.csv').drop([\"Unnamed: 0\"],axis=1)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckkvyHnup9et",
        "outputId": "c2fd0c9a-c835-4bea-81a1-fcc930acf906"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     psdtheta_1  psdalpha_1  psdbeta_1  psdtheta_2  psdalpha_2  psdbeta_2  \\\n",
            "0     -0.137607   -0.137238  -0.116997   -0.080612   -0.081118  -0.108773   \n",
            "1     -0.139174   -0.138685  -0.117599   -0.096207   -0.096338  -0.110293   \n",
            "2     -0.127690   -0.127539  -0.110420   -0.101203   -0.101259  -0.098381   \n",
            "3     -0.158972   -0.158123  -0.131111   -0.100674   -0.100739  -0.097964   \n",
            "4     -0.110480   -0.110713  -0.099031   -0.111506   -0.111337  -0.089051   \n",
            "..          ...         ...        ...         ...         ...        ...   \n",
            "409   -0.176673   -0.175428  -0.142822   -0.119956   -0.118711  -0.111964   \n",
            "410   -0.143317   -0.142784  -0.120602   -0.111610   -0.111338  -0.079139   \n",
            "411   -0.153161   -0.152451  -0.127275   -0.055160   -0.047706  -0.035399   \n",
            "412   -0.221893   -0.219656  -0.172804   -0.092856   -0.088311  -0.070856   \n",
            "413   -0.128817   -0.128628  -0.111106   -0.141103   -0.139356  -0.113828   \n",
            "\n",
            "     psdtheta_3  psdalpha_3  psdbeta_3  psdtheta_4  ...  psdbeta_12  \\\n",
            "0     -0.146683   -0.182929  -0.229771   -0.273779  ...   -0.275621   \n",
            "1     -0.119051   -0.104170  -0.091178   -0.132652  ...   -0.167682   \n",
            "2     -0.105765   -0.105699   0.042209   -0.162592  ...    0.018827   \n",
            "3     -0.069629   -0.030775  -0.003793   -0.164088  ...   -0.078810   \n",
            "4      0.049651    0.050012   0.054975   -0.120093  ...   -0.030801   \n",
            "..          ...         ...        ...         ...  ...         ...   \n",
            "409   -0.199767   -0.210899  -0.212342   -0.284140  ...    1.171011   \n",
            "410   -0.233932   -0.234307  -0.073831   -0.434450  ...    0.527647   \n",
            "411   -0.035928   -0.057263  -0.120834    0.057748  ...   -0.270302   \n",
            "412   -0.105453   -0.105761  -0.137604   -0.321064  ...   -0.218219   \n",
            "413   -0.203525   -0.201648  -0.033569   -0.421247  ...   -0.136474   \n",
            "\n",
            "     psdtheta_13  psdalpha_13  psdbeta_13  psdtheta_14  psdalpha_14  \\\n",
            "0      -0.243177    -0.242829   -0.232958    -0.219589    -0.219693   \n",
            "1      -0.197810    -0.203598   -0.209676    -0.200044    -0.200146   \n",
            "2      -0.210256    -0.209778   -0.165222    -0.150181    -0.150377   \n",
            "3      -0.231014    -0.230617   -0.195014    -0.193550    -0.193687   \n",
            "4      -0.145732    -0.145007   -0.186470    -0.016868    -0.017255   \n",
            "..           ...          ...         ...          ...          ...   \n",
            "409     0.016215     0.017675    0.024536    -0.059657    -0.059933   \n",
            "410    -0.251999    -0.251682   -0.247363     0.273257     0.272511   \n",
            "411    -0.112535    -0.111811   -0.106746     0.020441     0.020105   \n",
            "412    -0.259624    -0.259340   -0.255097    -0.153406    -0.153599   \n",
            "413    -0.006833     0.015250    0.260065    -0.090086    -0.077634   \n",
            "\n",
            "     psdbeta_14  Valence  Arousal  Dominance  \n",
            "0     -0.222478      1.0      0.0        0.0  \n",
            "1     -0.206911      0.0      0.0        0.0  \n",
            "2     -0.071193      1.0      1.0        1.0  \n",
            "3     -0.158883      1.0      0.0        0.0  \n",
            "4     -0.116913      1.0      1.0        1.0  \n",
            "..          ...      ...      ...        ...  \n",
            "409   -0.067176      0.0      0.0        0.0  \n",
            "410    0.258408      0.0      0.0        0.0  \n",
            "411    0.011488      0.0      0.0        0.0  \n",
            "412   -0.159238      0.0      0.0        1.0  \n",
            "413    0.113833      0.0      1.0        0.0  \n",
            "\n",
            "[414 rows x 45 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_X=df.iloc[:,0:-3]\n",
        "feature_V=df.iloc[:,-3]\n",
        "feature_A=df.iloc[:,-2]\n",
        "feature_D=df.iloc[:,-1]\n",
        "feature_XVD = pd.concat([feature_X, feature_V, feature_D], axis=1)\n",
        "feature_XAD = pd.concat([feature_X, feature_A, feature_D], axis=1)\n",
        "feature_XAV = pd.concat([feature_X, feature_V, feature_A], axis=1)\n"
      ],
      "metadata": {
        "id": "-3xxIMjxsbkk"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YFesfOK8ut67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_rate = 128\n",
        "window_size = 1280\n",
        "overlap = 256\n",
        "channel_len = 14\n",
        "classes = 2\n",
        "EEG_Electrodes = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4'] \n",
        "noOfSubjects =  23\n",
        "noOfVideoSequences= 18\n",
        "\n",
        "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
        "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
        "         'gamma': [30/(sampling_rate/2), 50/(sampling_rate/2)]}\n"
      ],
      "metadata": {
        "id": "ep5ZjzzAsbnG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"We need the following information to create MNE structure:\n",
        "    data ([ndarray]): [trials x chans x samples]\n",
        "    y ([ndarray]):    [class label array  [1, labels]]\n",
        "    sfreq ([int]):    [sampling frequency]\n",
        "    event_id ([dict]): [{1 :'pos', -1 : 'neg'} - class labels id]\n",
        "    chan_names ([list]): [channel names in a list of strings]\n",
        "\"\"\"                     \n",
        "\n",
        "n_channels = 14\n",
        "\n",
        "# Initialize an info structure\n",
        "info = mne.create_info(\n",
        "        ch_names = EEG_Electrodes,\n",
        "        ch_types = ['eeg']*n_channels,\n",
        "        sfreq    = sampling_rate\n",
        "        )   \n",
        "\n",
        "info.set_montage('standard_1020')\n",
        "print('Event created :', info) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbF1jfZRp9hP",
        "outputId": "089de7e2-63d1-405d-a986-9c926fda3679"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Event created : <Info | 8 non-empty values\n",
            " bads: []\n",
            " ch_names: AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4\n",
            " chs: 14 EEG\n",
            " custom_ref_applied: False\n",
            " dig: 17 items (3 Cardinal, 14 EEG)\n",
            " highpass: 0.0 Hz\n",
            " lowpass: 64.0 Hz\n",
            " meas_date: unspecified\n",
            " nchan: 14\n",
            " projs: []\n",
            " sfreq: 128.0 Hz\n",
            ">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a4qQMIQkti7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0qgMGG8Kti-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BnbReFqutjJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CNN**"
      ],
      "metadata": {
        "id": "p8_8rAmGoAKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_raw_model(nchan, nclasses, trial_length=960, l1=0):\n",
        "    \"\"\"\n",
        "    CNN model definition\n",
        "    \"\"\"\n",
        "    input_shape = (trial_length, nchan, 1)\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(40, (30, 1), activation=\"relu\", kernel_regularizer=regularizers.l1(l1), padding=\"same\", input_shape=input_shape))\n",
        "    model.add(Conv2D(40, (1, nchan), activation=\"relu\", kernel_regularizer=regularizers.l1(l1), padding=\"valid\"))\n",
        "    model.add(tf.keras.layers.GlobalAveragePooling2D((30, 1)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(80, activation=\"relu\"))\n",
        "    model.add(Dense(nclasses, activation=\"softmax\"))\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "pNGId_dGnwVv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_model(model, X, y, train_idx, test_idx, input_length=50, batch_size=32, epochs=30, steps_per_epoch=1000, callbacks=None):    \n",
        "    gc.collect()\n",
        "    return model.fit_generator(\n",
        "        nndata.crossval_gen(X,y, train_idx, input_length, batch_size),\n",
        "        validation_data=nndata.crossval_test(X, y, test_idx, input_length),\n",
        "        steps_per_epoch=steps_per_epoch, epochs=epochs, callbacks=callbacks                          \n",
        "    )"
      ],
      "metadata": {
        "id": "YjCtHb0EviVc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1pwIam6yO3Y",
        "outputId": "dd220b95-450d-4d2d-9f87-fb833851fb8b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: unknown command \"keras\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "nN63b73JviX5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN 2"
      ],
      "metadata": {
        "id": "wM4tGKx40q0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import argparse\n"
      ],
      "metadata": {
        "id": "vFXYMhh4vicq"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SCU(nn.Module):\n",
        "\n",
        "    def __init__(self, opt, num_classes):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=9, out_channels=16, kernel_size=5, stride=2),\n",
        "            nn.BatchNorm1d(num_features=16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Dropout(p=0.2))\n",
        "        \n",
        "        self.dense_layers = nn.Sequential(\n",
        "            nn.Linear(5984, 600),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(600, 60),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(60, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.layer1(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.dense_layers(out)     \n",
        "        return out"
      ],
      "metadata": {
        "id": "T7vCNvfb1M4U"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--n_epochs', type=int, default=50, help='number of epochs of training')\n",
        "parser.add_argument('--lr', type=float, default=0.00001, help='adam: learning rate')\n",
        "parser.add_argument('--dropout_level', type=float, default=0.5, help='dropout level')\n",
        "parser.add_argument('--w_decay', type=float, default=0.001, help='weight decay')\n",
        "parser.add_argument('--batch_size', type=int, default=10, help='batch size')\n",
        "parser.add_argument('--seed_n', type=int, default=74, help='seed number')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSnHnDASCMZM",
        "outputId": "9388684f-7b2a-4ba3-a21f-f7fb5e913c2b"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--seed_n'], dest='seed_n', nargs=None, const=None, default=74, type=<class 'int'>, choices=None, help='seed number', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from optparse import OptionParser\n",
        "...\n",
        "parser = OptionParser()\n",
        "parser.add_option(\"-f\", \"--file\", dest=\"filename\",\n",
        "                  help=\"write report to FILE\", metavar=\"FILE\")\n",
        "parser.add_option(\"-q\", \"--quiet\",\n",
        "                  action=\"store_false\", dest=\"verbose\", default=True,\n",
        "                  help=\"don't print status messages to stdout\")\n",
        "\n",
        "(opt, args) = parser.parse_args()"
      ],
      "metadata": {
        "id": "R238IFKz_75W"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--n_epochs', type=float, default=50, help='number of epochs of training')\n",
        "parser.add_argument('--lr', type=float, default=0.00001, help='adam: learning rate')\n",
        "parser.add_argument('--dropout_level', type=float, default=0.5, help='dropout level')\n",
        "parser.add_argument('--w_decay', type=float, default=0.001, help='weight decay')\n",
        "parser.add_argument('--batch_size', type=float, default=10, help='batch size')\n",
        "parser.add_argument('--seed_n', type=float, default=74, help='seed number')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEZ-BdV0_rCm",
        "outputId": "17ea233c-d6fb-4337-c5b3-4e14b8a857f4"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--seed_n'], dest='seed_n', nargs=None, const=None, default=74, type=<class 'float'>, choices=None, help='seed number', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(opt))\n",
        "print(opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9n-ldTv9Mmq",
        "outputId": "e3c6fc4f-80f9-4722-c9c6-5b9c289786c6"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'optparse.Values'>\n",
            "{'filename': '/root/.local/share/jupyter/runtime/kernel-1a4175cf-f310-489a-8f6d-03eb0d016136.json', 'verbose': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(opt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R66xZn7DR3l",
        "outputId": "75305105-9700-40f9-e816-a6cf773d15d4"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_update', '_update_careful', '_update_loose', 'ensure_value', 'filename', 'read_file', 'read_module', 'verbose']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device  = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "b_8fOch6_wUV"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "Xo26RosfDqsC"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(opt.seed_n)\n",
        "torch.cuda.manual_seed(opt.seed_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "8VgVylfjDt8z",
        "outputId": "970772ea-efd4-4717-f0f3-f45b0da1dfad"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-6e96fdea3a37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Values' object has no attribute 'seed_n'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2"
      ],
      "metadata": {
        "id": "iJDBfV-B03yT"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2"
      ],
      "metadata": {
        "id": "GuqEMgyS9tqV"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DnwLghRR9IOR"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_SCU(X_train, y_train):\n",
        "\n",
        "    # convert NumPy Array to Torch Tensor\n",
        "    train_input = torch.from_numpy(X_train)\n",
        "    train_label = torch.from_numpy(y_train)\n",
        "\n",
        "    # create the data loader for the training set\n",
        "    trainset = torch.utils.data.TensorDataset(train_input, train_label)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=2, shuffle=True, num_workers=4)\n",
        "    \n",
        "    cnn = SCU(opt, num_classes).to(device)\n",
        "    cnn.train()\n",
        "    # Loss and Optimizer\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(cnn.parameters(), lr=opt.lr, weight_decay=opt.w_decay)\n",
        "\n",
        "    # loop through the required number of epochs\n",
        "    for epoch in range(opt.n_epochs):\n",
        "\n",
        "        # loop through the batches\n",
        "        cumulative_accuracy = 0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # format the data from the dataloader\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            inputs = inputs.float()\n",
        "            \n",
        "            # Forward + Backward + Optimize\n",
        "            optimizer.zero_grad()\n",
        "            outputs = cnn(inputs)\n",
        "\n",
        "            loss = ce_loss(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # calculate the accuracy over the training batch\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            \n",
        "            cumulative_accuracy += get_accuracy(labels, predicted)\n",
        "    \n",
        "    return cnn\n"
      ],
      "metadata": {
        "id": "l9p0TPGj0306"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_SCU(cnn, X_test, y_test):\n",
        "\n",
        "     # convert NumPy Array to Torch Tensor\n",
        "    test_input = torch.from_numpy(X_test)\n",
        "    test_label = torch.from_numpy(y_test)\n",
        "\n",
        "    # create the data loader for the test set\n",
        "    testset = torch.utils.data.TensorDataset(test_input, test_label)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=2, shuffle=False, num_workers=4)\n",
        "\n",
        "    cnn.eval()\n",
        "    test_cumulative_accuracy = 0\n",
        "    for i, data in enumerate(testloader, 0):\n",
        "        # format the data from the dataloader\n",
        "        test_inputs, test_labels = data\n",
        "        test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
        "        test_inputs = test_inputs.float()    \n",
        "\n",
        "        test_outputs = cnn(test_inputs)\n",
        "        _, test_predicted = torch.max(test_outputs, 1)    \n",
        "        \n",
        "        test_acc = get_accuracy(test_labels,test_predicted)\n",
        "        test_cumulative_accuracy += test_acc\n",
        "\n",
        "    return test_cumulative_accuracy, len(testloader)\n"
      ],
      "metadata": {
        "id": "jhaPf4dV033D"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhUQ8wgS7lgW",
        "outputId": "430450a4-a09d-4053-c68d-6e0972d5fe33"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 35 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 54.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=f05023a2d8c02acfefdd8f0a96ccbdac065e2302251a27f2d32593d2f66e1115\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql.session import SparkSession\n",
        "sc = SparkContext('local')\n",
        "spark = SparkSession(sc)"
      ],
      "metadata": {
        "id": "xERqblEr7i0l"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Just right before the actual usage\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "cnn = SCU(opt, num_classes).to(device)\n",
        "cnn.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Kb7ntqi-YF3",
        "outputId": "8d4b3636-ac6d-4ccf-bbba-5e7224593d83"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SCU(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv1d(9, 16, kernel_size=(5,), stride=(2,))\n",
              "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (dense_layers): Sequential(\n",
              "    (0): Linear(in_features=5984, out_features=600, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=600, out_features=60, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.2, inplace=False)\n",
              "    (6): Linear(in_features=60, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iRhUvsMa-YQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection \n",
        "from sklearn.model_selection import train_test_split   \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # data loading\n",
        "    #Arousal->>> Valence, dominance included in the feature X\n",
        "\n",
        "    feature_XVD = pd.concat([feature_X, feature_V, feature_D], axis=1)\n",
        "    feature_A=df.iloc[:,-2]\n",
        "    print(type(feature_A))\n",
        "    print(type(feature_XVD))\n",
        "\n",
        "    x5D = np.array(feature_XVD)\n",
        "    y5D = np.array(feature_A)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x5D, y5D, train_size=0.8)\n",
        "\n",
        "\n",
        "    #feature_XVD = np.swapaxes(feature_XVD,0,1)\n",
        "\n",
        "    # split the data  training and testing\n",
        "  #  X_train, X_test, y_train, y_test = train_test_split(feature_XVD, feature_A, test_size=0.2)\n",
        "\n",
        "    # training\n",
        "    cnn = train_SCU(X_train, y_train)\n",
        "\n",
        "    # testing\n",
        "    test_cumulative_accuracy, ntest = test_SCU(cnn, X_test, y_test)\n",
        "\n",
        "    print(f\"Test Accuracy: {test_cumulative_accuracy/ntest*100}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "QSKlwV0_1FtV",
        "outputId": "53b27641-0019-48ec-9db9-8868cc0c0e96"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-143-f343048f1434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_SCU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-140-aa0da1005b77>\u001b[0m in \u001b[0;36mtrain_SCU\u001b[0;34m(X_train, y_train)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Loss and Optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mce_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# loop through the required number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Values' object has no attribute 'lr'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GXW4_HgV1Fxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H-5LNoxn1F0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t2IgZbRp1F2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ISaJ2Q-U035U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}